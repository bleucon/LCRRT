{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "import torch.backends.cudnn as cudnn\n",
    "from lib.models.S2 import SR, SP\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.models.transformer import build_transformer\n",
    "from lib.models.backbone import *\n",
    "from lib.models.pose_transformer import MLP\n",
    "\n",
    "# cudnn related setting\n",
    "cudnn.benchmark = True\n",
    "cudnn.determinstic = False\n",
    "cudnn.enabled = True\n",
    "\n",
    "transformer = build_transformer(hidden_dim=256, dropout=0.0, nheads=8, dim_feedforward=2048,\n",
    "                                enc_layers=6, dec_layers=6, pre_norm=False,\n",
    "                                num_clusters=9, use_sr=True)\n",
    "backbone = ResNetBackbone('resnet50', train_backbone=True, return_interm_layers=True, pretrained=True, dilation=False)\n",
    "position_embedding = build_position_encoding(256, 'sine')\n",
    "backbone = Joiner(backbone, position_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "src, pos = backbone(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PoseTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone, transformer, **kwargs):\n",
    "        super(PoseTransformer, self).__init__()\n",
    "        self.num_queries = 68\n",
    "        self.num_classes = 68\n",
    "        self.transformer = transformer\n",
    "        self.backbone = backbone\n",
    "        hidden_dim = transformer.d_model\n",
    "        self.class_embed = nn.Linear(hidden_dim, self.num_classes + 1)\n",
    "        self.kpt_embed = MLP(hidden_dim, hidden_dim, 2, 3)\n",
    "        self.query_embed = nn.Embedding(self.num_queries, hidden_dim)\n",
    "        self.aux_loss = extra.AUX_LOSS\n",
    "\n",
    "        self.num_feature_levels = extra.NUM_FEATURE_LEVELS\n",
    "        if self.num_feature_levels > 1:\n",
    "            num_backbone_outs = len(backbone.num_channels)\n",
    "            input_proj_list = []\n",
    "            for _ in range(num_backbone_outs):\n",
    "                in_channels = backbone.num_channels[_]\n",
    "                input_proj_list.append(nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, hidden_dim, kernel_size=1),\n",
    "                    nn.GroupNorm(32, hidden_dim),\n",
    "                ))\n",
    "            for _ in range(self.num_feature_levels - num_backbone_outs):\n",
    "                input_proj_list.append(nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, hidden_dim, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.GroupNorm(32, hidden_dim),\n",
    "                ))\n",
    "                in_channels = hidden_dim\n",
    "            self.input_proj = nn.ModuleList(input_proj_list)\n",
    "            # 初始化\n",
    "            prior_prob = 0.01\n",
    "            bias_value = -math.log((1 - prior_prob) / prior_prob)\n",
    "            self.class_embed.bias.data = torch.ones(self.num_classes + 1) * bias_value\n",
    "            nn.init.constant_(self.kpt_embed.layers[-1].weight.data, 0)\n",
    "            nn.init.constant_(self.kpt_embed.layers[-1].bias.data, 0)\n",
    "            for proj in self.input_proj:\n",
    "                nn.init.xavier_uniform_(proj[0].weight, gain=1)\n",
    "                nn.init.constant_(proj[0].bias, 0)\n",
    "            num_pred = transformer.decoder.num_layers  ##解码器的层数\n",
    "            self.class_embed = nn.ModuleList([self.class_embed for _ in range(num_pred)])  ## 每一个解码层都添加全连接网络进行预测\n",
    "            self.kpt_embed = nn.ModuleList([self.kpt_embed for _ in range(num_pred)])\n",
    "        else:\n",
    "            self.input_proj = nn.Conv2d(self.backbone.num_channels[0], hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        src, pos = self.backbone(x)\n",
    "        # features, pos = self.backbone(x)\n",
    "        # srcs = []\n",
    "        # for l, feat in enumerate(features):\n",
    "        #     srcs.append(self.input_proj[l](feat))\n",
    "        plt.imshow(np.transpose(x[0].cpu().numpy(), (1, 2, 0)))\n",
    "\n",
    "        hs = self.transformer(self.input_proj(src[-1]), None,\n",
    "                              self.query_embed.weight, pos[-1])\n",
    "\n",
    "        # hs = self.transformer(srcs, None,\n",
    "        #                       self.query_embed.weight, pos)\n",
    "\n",
    "        outputs_class = self.class_embed(hs)\n",
    "        outputs_coord = self.kpt_embed(hs).sigmoid()\n",
    "        # outputs_classes = []\n",
    "        # outputs_coords = []\n",
    "        # for lvl in range(hs.shape[0]):\n",
    "        #     outputs_class = self.class_embed[lvl](hs[lvl])\n",
    "        #     tmp = self.kpt_embed[lvl](hs[lvl])\n",
    "        #     outputs_coord = tmp.sigmoid()\n",
    "        #     outputs_classes.append(outputs_class)\n",
    "        #     outputs_coords.append(outputs_coord)\n",
    "        #\n",
    "        # outputs_class = torch.stack(outputs_classes)\n",
    "        # outputs_coord = torch.stack(outputs_coords)\n",
    "\n",
    "        out = {\n",
    "            'pred_logits': outputs_class[-1],\n",
    "            'pred_coords': outputs_coord[-1]\n",
    "            }\n",
    "\n",
    "        # outs = []\n",
    "        # for i in range(len(outputs_class)):\n",
    "        #     out = {\n",
    "        #         'pred_logits': outputs_class[i],\n",
    "        #         'pred_coords': outputs_coord[i]}\n",
    "        #\n",
    "        if self.aux_loss:\n",
    "            out['aux_outputs'] = self._set_aux_loss(\n",
    "                outputs_class,\n",
    "                outputs_coord)\n",
    "        #     outs.append(out)\n",
    "        return out\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def _set_aux_loss(self,\n",
    "                      outputs_class,\n",
    "                      outputs_coord):\n",
    "        # this is a workaround to make torchscript happy, as torchscript\n",
    "        # doesn't support dictionary with non-homogeneous values, such\n",
    "        # as a dict having both a Tensor and a list.\n",
    "        return [{'pred_logits': a, 'pred_coords': b}\n",
    "                for a, b in zip(outputs_class[:-1], outputs_coord[:-1])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = PoseTransformer()\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
    "\n",
    "matcher = build_matcher(config.MODEL.NUM_JOINTS)\n",
    "weight_dict = {'loss_ce': 1, 'loss_kpts': config.MODEL.EXTRA.KPT_LOSS_COEF}\n",
    "if config.MODEL.EXTRA.AUX_LOSS:\n",
    "    aux_weight_dict = {}\n",
    "    for i in range(config.MODEL.EXTRA.DEC_LAYERS - 1):\n",
    "        aux_weight_dict.update(\n",
    "            {k + f'_{i}': v for k, v in weight_dict.items()})\n",
    "    weight_dict.update(aux_weight_dict)\n",
    "criterion = SetCriterion(model.num_classes, matcher, weight_dict, config.MODEL.EXTRA.EOS_COEF, [\n",
    "    'labels',\n",
    "    'kpts',\n",
    "    'cardinality'\n",
    "]).cuda()\n",
    "\n",
    "gpus = list(config.GPUS)\n",
    "model = nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "\n",
    "optimizer = utils.get_optimizer(config, model)\n",
    "best_nme = 100\n",
    "last_epoch = config.TRAIN.BEGIN_EPOCH\n",
    "if config.TRAIN.RESUME:\n",
    "    model_state_file = os.path.join(final_output_dir,\n",
    "                                    'latest.pth')\n",
    "    if os.path.isfile(model_state_file):\n",
    "        checkpoint = torch.load(model_state_file)\n",
    "        last_epoch = checkpoint['epoch']\n",
    "        best_nme = checkpoint['best_nme']\n",
    "        model.module.load_state_dict(checkpoint['state_dict'].module.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint (epoch {})\"\n",
    "              .format(checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")\n",
    "\n",
    "if isinstance(config.TRAIN.LR_STEP, list):\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, config.TRAIN.LR_STEP,\n",
    "        config.TRAIN.LR_FACTOR, last_epoch-1\n",
    "    )\n",
    "else:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, config.TRAIN.LR_STEP,\n",
    "        config.TRAIN.LR_FACTOR, last_epoch-1\n",
    "    )\n",
    "dataset_type = get_dataset(config)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=dataset_type(config,\n",
    "                         is_train=True),\n",
    "    batch_size=config.TRAIN.BATCH_SIZE_PER_GPU*len(gpus),\n",
    "    shuffle=config.TRAIN.SHUFFLE,\n",
    "    num_workers=config.WORKERS,\n",
    "    pin_memory=config.PIN_MEMORY)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=dataset_type(config,\n",
    "                         is_train=False),\n",
    "    batch_size=config.TEST.BATCH_SIZE_PER_GPU*len(gpus),\n",
    "    shuffle=False,\n",
    "    num_workers=config.WORKERS,\n",
    "    pin_memory=config.PIN_MEMORY\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}